{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BM25 Search\n",
    "\n",
    "## BM25 Formula\n",
    "\n",
    "The BM25 relevance score for a document $d$ and a query $q$ is computed as:\n",
    "\n",
    "$$\n",
    "\\text{BM25}(d, q) = \\sum_{t \\in q} \\text{IDF}(t) \\cdot \\frac{f_{t, d} \\cdot (k_1 + 1)}{f_{t, d} + k_1 \\cdot (1 - b + b \\cdot \\frac{|d|}{\\text{avgdl}})}\n",
    "$$\n",
    "\n",
    "### Where:\n",
    "1. **$t$**: A term in the query.\n",
    "2. **$f_{t, d}$**: The frequency of term $t$ in document $d$ (term frequency).\n",
    "3. **$|d|$**: The length of document $d$ (number of terms in $d$).\n",
    "4. **$\\text{avgdl}$**: The average document length in the corpus.\n",
    "5. **$\\text{IDF}(t)$**: The inverse document frequency of term $t$, calculated as:\n",
    "   $$\n",
    "   \\text{IDF}(t) = \\log\\left(\\frac{N - n_t + 0.5}{n_t + 0.5} + 1\\right)\n",
    "   $$\n",
    "   - $N$: Total number of documents.\n",
    "   - $n_t$: Number of documents containing term $t$.\n",
    "6. **$k_1$**: Controls the term frequency saturation (commonly set to 1.2).\n",
    "7. **$b$**: Controls the document length normalization (commonly set to 0.75).\n",
    "\n",
    "\n",
    "[Explanation](https://www.elastic.co/blog/practical-bm25-part-2-the-bm25-algorithm-and-its-variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differences between BM25 and TF-IDF IDF formula:\n",
    "\n",
    "The IDF formula in BM25 is different from the one used in TF-IDF because BM25 is specifically designed for ranking documents in a search setting. Its IDF calculation incorporates additional considerations to address some of the limitations in the standard TF-IDF formula. Here's a breakdown of the differences and their significance:\n",
    "\n",
    "---\n",
    "\n",
    "### TF-IDF IDF Formula\n",
    "$$\n",
    "\\text{IDF}(t) = \\log\\left(\\frac{N}{n_t}\\right)\n",
    "$$\n",
    "\n",
    "- **$N$:** Total number of documents in the corpus.\n",
    "- **$n_t$:** Number of documents containing term $t$.\n",
    "\n",
    "This formula assigns a higher weight to rare terms (low $n_t$) and a lower weight to frequent terms (high $n_t$). However, it has limitations:\n",
    "1. **Division by Zero Risk:** If $n_t = 0$, the formula becomes undefined.\n",
    "2. **Unbounded Values:** The result can become arbitrarily large for very rare terms.\n",
    "3. **No Smoothing:** Doesn't account for cases where terms are extremely rare but still have some presence.\n",
    "\n",
    "---\n",
    "\n",
    "### BM25 IDF Formula\n",
    "$$\n",
    "\\text{IDF}(t) = \\log\\left(\\frac{N - n_t + 0.5}{n_t + 0.5} + 1\\right)\n",
    "$$\n",
    "\n",
    "- Adds **0.5** to both numerator and denominator to:\n",
    "  - Smooth values and prevent division by zero.\n",
    "  - Ensure terms with very low $n_t$ don’t dominate excessively.\n",
    "  \n",
    "- Includes $N - n_t + 0.5$, which considers the number of documents that *do not* contain $t$. This adjustment:\n",
    "  - Gives a more balanced score when $t$ appears in many documents.\n",
    "  - Reduces the impact of terms that are either very common or very rare.\n",
    "\n",
    "---\n",
    "\n",
    "### Why BM25's IDF is Better for Search\n",
    "1. **Avoids Extreme Scores:**  \n",
    "   BM25's IDF formula avoids overly penalizing terms that appear in many documents while ensuring rare terms still get higher weights.\n",
    "   \n",
    "2. **Smoothing for Robustness:**  \n",
    "   The addition of $0.5$ ensures robustness in small datasets where $n_t$ can be 0 or very small.\n",
    "\n",
    "3. **Balances Common vs. Rare Terms:**  \n",
    "   - Standard TF-IDF can overemphasize rare terms.\n",
    "   - BM25 dampens this effect, making it better suited for search where a mix of common and rare terms might be relevant.\n",
    "\n",
    "---\n",
    "\n",
    "### Practical Example\n",
    "\n",
    "#### Dataset\n",
    "- $N = 100$ documents\n",
    "- $n_t = 50$ (term appears in half the documents)\n",
    "\n",
    "#### IDF Comparison\n",
    "- **TF-IDF:**  \n",
    "  $$\n",
    "  \\text{IDF} = \\log\\left(\\frac{100}{50}\\right) = \\log(2) \\approx 0.693\n",
    "  $$\n",
    "\n",
    "- **BM25:**  \n",
    "  $$\n",
    "  \\text{IDF} = \\log\\left(\\frac{100 - 50 + 0.5}{50 + 0.5} + 1\\right) = \\log\\left(\\frac{50.5}{50.5} + 1\\right) = \\log(2) \\approx 0.693\n",
    "  $$\n",
    "\n",
    "Here, both are similar because $n_t$ is moderate.\n",
    "\n",
    "#### For Rare Term ($n_t = 1$):\n",
    "- **TF-IDF:**  \n",
    "  $$\n",
    "  \\text{IDF} = \\log\\left(\\frac{100}{1}\\right) = \\log(100) \\approx 4.605\n",
    "  $$\n",
    "\n",
    "- **BM25:**  \n",
    "  $$\n",
    "  \\text{IDF} = \\log\\left(\\frac{100 - 1 + 0.5}{1 + 0.5} + 1\\right) = \\log\\left(\\frac{99.5}{1.5} + 1\\right) = \\log(67.33) \\approx 4.208\n",
    "  $$\n",
    "\n",
    "BM25 gives a slightly lower score, smoothing the impact of very rare terms.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Takeaways\n",
    "- **TF-IDF IDF:** Simple but can overemphasize rare terms and lacks robustness.\n",
    "- **BM25 IDF:** Smoothed and balanced, making it more suitable for real-world search and ranking tasks. \n",
    "\n",
    "BM25's IDF is tailored for document ranking, where the balance between common and rare terms is crucial for relevance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intuition Behind $f(t, d)$ and $k_1$ in BM25\n",
    "\n",
    "BM25 builds on the idea of term frequency ($f(t, d)$) and adds the parameter $k_1$ to fine-tune how term frequency impacts the relevance score. Here’s an intuitive breakdown:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. $f(t, d)$: Term Frequency\n",
    "- **What is it?**  \n",
    "  $f(t, d)$ is the **raw count** of how many times a term $t$ appears in a document $d$. For example:\n",
    "  - If the term \"apple\" appears 5 times in a document, $f(\\text{\"apple\"}, d) = 5$.\n",
    "\n",
    "- **Why does it matter?**  \n",
    "  Higher term frequency often means the term is more important in the document. For example:\n",
    "  - A document mentioning \"apple\" 20 times is likely more about apples than a document mentioning it once.\n",
    "\n",
    "- **Limitations of Raw Term Frequency:**  \n",
    "  If we only use $f(t, d)$, terms with very high frequencies could dominate the score, even if the extra appearances don’t add much value to the document's relevance.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. $k_1$: Term Frequency Saturation\n",
    "- **What is it?**  \n",
    "  $k_1$ is a **tuning parameter** that controls how much weight we give to term frequency. It introduces a \"saturation effect,\" meaning the score doesn't grow linearly with $f(t, d)$.\n",
    "\n",
    "- **Why is it needed?**  \n",
    "  Beyond a certain point, repeating a term doesn't necessarily make a document more relevant. For example:\n",
    "  - A document mentioning \"apple\" 50 times is probably not 50 times more relevant than one mentioning it 10 times.\n",
    "\n",
    "- **How it works:**  \n",
    "  The term frequency $f(t, d)$ is scaled using $k_1$ in BM25:\n",
    "  $$\n",
    "  \\text{TF factor} = \\frac{f(t, d)}{f(t, d) + k_1}\n",
    "  $$\n",
    "  - When $f(t, d)$ is **low**, the score increases almost proportionally with $f(t, d)$.\n",
    "  - When $f(t, d)$ is **high**, the denominator (with $k_1$) dampens the effect, preventing runaway scores.\n",
    "\n",
    "---\n",
    "\n",
    "### Impact of \\( k_1 \\):\n",
    "- **Small $k_1$:**  \n",
    "  - Makes BM25 behave more like a **binary match** — it cares less about term frequency.  \n",
    "  - Example: Whether \"apple\" appears 2 times or 10 times, the score won't change much.\n",
    "- **Large $k_1$:**  \n",
    "  - Places **more emphasis** on term frequency but still with diminishing returns.  \n",
    "  - Example: A document mentioning \"apple\" 20 times gets a higher score than one mentioning it 10 times, but the effect isn't linear.\n",
    "\n",
    "---\n",
    "\n",
    "### Intuition Through an Example\n",
    "\n",
    "Imagine two documents about fruits:\n",
    "\n",
    "#### Document 1:\n",
    "- Mentions \"apple\" 3 times.\n",
    "\n",
    "#### Document 2:\n",
    "- Mentions \"apple\" 15 times.\n",
    "\n",
    "#### With $k_1 = 1.5$:\n",
    "- For Document 1:\n",
    "  $$\n",
    "  \\text{TF factor} = \\frac{3}{3 + 1.5} = \\frac{3}{4.5} \\approx 0.67\n",
    "  $$\n",
    "- For Document 2:\n",
    "  $$\n",
    "  \\text{TF factor} = \\frac{15}{15 + 1.5} = \\frac{15}{16.5} \\approx 0.91\n",
    "  $$\n",
    "\n",
    "Notice that the jump from 3 to 15 repetitions increases the score, but **not proportionally**.\n",
    "\n",
    "#### With $k_1 = 0.5$:\n",
    "- For Document 1:\n",
    "  $$\n",
    "  \\text{TF factor} = \\frac{3}{3 + 0.5} = \\frac{3}{3.5} \\approx 0.86\n",
    "  $$\n",
    "- For Document 2:\n",
    "  $$\n",
    "  \\text{TF factor} = \\frac{15}{15 + 0.5} = \\frac{15}{15.5} \\approx 0.97\n",
    "  $$\n",
    "\n",
    "With a smaller $k_1$, the effect of term frequency is further reduced, and the scores for the two documents become closer.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Takeaways:\n",
    "1. $f(t, d)$:  \n",
    "   Measures how important a term is in a document based on its frequency.\n",
    "   \n",
    "2. $k_1$:  \n",
    "   Smooths out the impact of $f(t, d)$, ensuring that term frequency doesn’t dominate the scoring process excessively.\n",
    "\n",
    "3. **Together:**  \n",
    "   BM25 balances relevance:\n",
    "   - Accounts for frequency when a term appears a few times.\n",
    "   - Dampens the effect when the term is repeated excessively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3176789  1.10212021 0.         0.         0.96909597 0.\n",
      " 0.96909597 0.         0.         0.3176789  0.56864878 0.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['banana', 'mango', 'banana'],\n",
       " ['apple', 'banana', 'mango'],\n",
       " ['apple', 'banana', 'mango'],\n",
       " ['cherry', 'cherry', 'mango', 'cherry'],\n",
       " ['apple', 'banana', 'apple']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "corpus = [\n",
    "    \"Apple Apple Banana\",\n",
    "    \"Banana Mango Banana\",\n",
    "    \"Cherry Cherry Cherry\",\n",
    "    \"Grapes Grapes Berries Grapes\",\n",
    "    \"Apple Banana Mango\",\n",
    "    \"Blueberries Strawberries Apple\",\n",
    "    \"Apple Banana Mango\",\n",
    "    \"Grapes Grapes Grapes\",\n",
    "    \"Blueberries Apple Strawberries\",\n",
    "    \"Apple Banana Apple\",\n",
    "    \"Cherry Cherry Mango Cherry\",\n",
    "    \"Blueberries Strawberries Cherry\",\n",
    "]\n",
    "tokenized_corpus = [doc.lower().split(\" \") for doc in corpus]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "query = \"banana mango\"\n",
    "tokenized_query = query.lower().split(\" \")\n",
    "\n",
    "doc_scores = bm25.get_scores(tokenized_query)\n",
    "print(doc_scores)\n",
    "\n",
    "docs = bm25.get_top_n(tokenized_query, tokenized_corpus, n=5)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25 from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'banana': 5, 'apple': 6, 'mango': 4, 'cherry': 3, 'grapes': 2, 'berries': 1, 'blueberries': 3, 'strawberries': 3}\n",
      "3.1666666666666665\n",
      "[{'apple': 2, 'banana': 1}, {'banana': 2, 'mango': 1}, {'cherry': 3}, {'grapes': 3, 'berries': 1}, {'apple': 1, 'banana': 1, 'mango': 1}, {'blueberries': 1, 'strawberries': 1, 'apple': 1}, {'apple': 1, 'banana': 1, 'mango': 1}, {'grapes': 3}, {'blueberries': 1, 'apple': 1, 'strawberries': 1}, {'apple': 2, 'banana': 1}, {'cherry': 3, 'mango': 1}, {'blueberries': 1, 'strawberries': 1, 'cherry': 1}]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class BM25:\n",
    "    def __init__(self, corpus: list[list[str]], k1: float = 1.2, b: float = 0.75):\n",
    "        self.corpus = corpus\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.N = len(corpus)\n",
    "        self.avg_dl = None\n",
    "\n",
    "        self.nd, self.document_frequencies = self.initialize(self.corpus)\n",
    "        self.idf = self.calculate_idf(self.nd)\n",
    "\n",
    "    def initialize(self, corpus):\n",
    "        nd = {}\n",
    "        document_frequencies = []\n",
    "        total_doc_len = 0\n",
    "        for doc in corpus:\n",
    "            total_doc_len += len(doc)\n",
    "            document_frequencies.append(dict(Counter(doc)))\n",
    "            for term in set(doc):\n",
    "                if term not in nd:\n",
    "                    nd[term] = 1\n",
    "                else: \n",
    "                    nd[term] += 1\n",
    "\n",
    "        self.avg_dl = total_doc_len / self.N\n",
    "        return nd, document_frequencies\n",
    "\n",
    "    def calculate_idf(self, nd):\n",
    "        idf = {}\n",
    "        for term in nd:\n",
    "            idf[term] = math.log((self.N - nd[term] + 0.5) / (nd[term] + 0.5) + 1)\n",
    "\n",
    "        return idf\n",
    "    \n",
    "    def get_scores(self, query: list[str]):\n",
    "        for q in query:\n",
    "            idf_q = self.idf[q]\n",
    "            f_q = self.document_frequencies\n",
    "\n",
    "\n",
    "bm25 = BM25(tokenized_corpus)\n",
    "print(bm25.nd)\n",
    "print(bm25.avg_dl)\n",
    "print(bm25.document_frequencies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
