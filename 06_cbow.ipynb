{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Bag of Words (CBOW) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"Natural Language Processing is a fascinating field of study that has been evolving rapidly over the past few decades.\",\n",
    "    \"Machine learning provides powerful tools for automating tasks and making predictions from data.\",\n",
    "    \"Text data is often messy and unstructured, which makes it challenging to analyze and understand without the right tools.\",\n",
    "    \"Deep learning models have shown remarkable success in understanding complex patterns in data, especially for tasks related to NLP.\",\n",
    "    \"I love building machine learning models and experimenting with different techniques to improve their performance.\",\n",
    "    \"Clean and properly preprocessed data is essential for building successful machine learning models that generalize well.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Furthermore , as an encouragement to revisionist thinking , it manifestly is fair to admit that any fraternity has a constitutional right to refuse to accept persons it dislikes .',\n",
       " 'The Unitarian clergy were an exclusive club of cultivated gentlemen -- as the term was then understood in the Back Bay -- and Parker was definitely not a gentleman , either in theology or in manners .',\n",
       " 'Ezra Stiles Gannett , an honorable representative of the sanhedrin , addressed himself frankly to the issue in 1845 , insisting that Parker should not be persecuted or calumniated and that in this republic no power to restrain him by force could exist .',\n",
       " \"Even so , Gannett judiciously argued , the Association could legitimately decide that Parker `` should not be encouraged nor assisted in diffusing his opinions by those who differ from him in regard to their correctness '' .\",\n",
       " 'We today are not entitled to excoriate honest men who believed Parker to be downright pernicious and who barred their pulpits against his demand to poison the minds of their congregations .']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"brown.csv\")\n",
    "corpus = df['tokenized_text'].tolist()\n",
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['furthermore',\n",
       "  'encouragement',\n",
       "  'revisionist',\n",
       "  'thinking',\n",
       "  'manifestly',\n",
       "  'fair',\n",
       "  'admit',\n",
       "  'fraternity',\n",
       "  'constitutional',\n",
       "  'right',\n",
       "  'refuse',\n",
       "  'accept',\n",
       "  'persons',\n",
       "  'dislikes'],\n",
       " ['unitarian',\n",
       "  'clergy',\n",
       "  'exclusive',\n",
       "  'club',\n",
       "  'cultivated',\n",
       "  'gentlemen',\n",
       "  'term',\n",
       "  'understood',\n",
       "  'bay',\n",
       "  'parker',\n",
       "  'definitely',\n",
       "  'gentleman',\n",
       "  'theology',\n",
       "  'manners'],\n",
       " ['ezra',\n",
       "  'stiles',\n",
       "  'gannett',\n",
       "  'honorable',\n",
       "  'representative',\n",
       "  'sanhedrin',\n",
       "  'addressed',\n",
       "  'frankly',\n",
       "  'issue',\n",
       "  '1845',\n",
       "  'insisting',\n",
       "  'parker',\n",
       "  'persecuted',\n",
       "  'calumniated',\n",
       "  'republic',\n",
       "  'power',\n",
       "  'restrain',\n",
       "  'force',\n",
       "  'exist'],\n",
       " ['gannett',\n",
       "  'judiciously',\n",
       "  'argued',\n",
       "  'association',\n",
       "  'legitimately',\n",
       "  'decide',\n",
       "  'parker',\n",
       "  'encouraged',\n",
       "  'assisted',\n",
       "  'diffusing',\n",
       "  'opinions',\n",
       "  'differ',\n",
       "  'regard',\n",
       "  'correctness'],\n",
       " ['today',\n",
       "  'entitled',\n",
       "  'excoriate',\n",
       "  'honest',\n",
       "  'men',\n",
       "  'believed',\n",
       "  'parker',\n",
       "  'downright',\n",
       "  'pernicious',\n",
       "  'barred',\n",
       "  'pulpits',\n",
       "  'demand',\n",
       "  'poison',\n",
       "  'minds',\n",
       "  'congregations']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def clean_text(documents: list[str]):\n",
    "    cleaned_docs = []\n",
    "    for doc in documents:\n",
    "        doc_text = re.sub(r\"[^\\w\\s]\", \"\", doc.lower())\n",
    "        doc_nlp = nlp(doc_text)\n",
    "        filtered_text = [token.text for token in doc_nlp if not token.is_stop and token.text.strip()]\n",
    "        cleaned_docs.append(filtered_text)\n",
    "\n",
    "    return cleaned_docs\n",
    "\n",
    "cleaned_corpus = clean_text(corpus[:5])\n",
    "cleaned_corpus[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'furthermore': 0, 'encouragement': 1, 'revisionist': 2, 'thinking': 3, 'manifestly': 4, 'fair': 5, 'admit': 6, 'fraternity': 7, 'constitutional': 8, 'right': 9, 'refuse': 10, 'accept': 11, 'persons': 12, 'dislikes': 13, 'unitarian': 14, 'clergy': 15, 'exclusive': 16, 'club': 17, 'cultivated': 18, 'gentlemen': 19, 'term': 20, 'understood': 21, 'bay': 22, 'parker': 23, 'definitely': 24, 'gentleman': 25, 'theology': 26, 'manners': 27, 'ezra': 28, 'stiles': 29, 'gannett': 30, 'honorable': 31, 'representative': 32, 'sanhedrin': 33, 'addressed': 34, 'frankly': 35, 'issue': 36, '1845': 37, 'insisting': 38, 'persecuted': 39, 'calumniated': 40, 'republic': 41, 'power': 42, 'restrain': 43, 'force': 44, 'exist': 45, 'judiciously': 46, 'argued': 47, 'association': 48, 'legitimately': 49, 'decide': 50, 'encouraged': 51, 'assisted': 52, 'diffusing': 53, 'opinions': 54, 'differ': 55, 'regard': 56, 'correctness': 57, 'today': 58, 'entitled': 59, 'excoriate': 60, 'honest': 61, 'men': 62, 'believed': 63, 'downright': 64, 'pernicious': 65, 'barred': 66, 'pulpits': 67, 'demand': 68, 'poison': 69, 'minds': 70, 'congregations': 71}\n",
      "{0: 'furthermore', 1: 'encouragement', 2: 'revisionist', 3: 'thinking', 4: 'manifestly', 5: 'fair', 6: 'admit', 7: 'fraternity', 8: 'constitutional', 9: 'right', 10: 'refuse', 11: 'accept', 12: 'persons', 13: 'dislikes', 14: 'unitarian', 15: 'clergy', 16: 'exclusive', 17: 'club', 18: 'cultivated', 19: 'gentlemen', 20: 'term', 21: 'understood', 22: 'bay', 23: 'parker', 24: 'definitely', 25: 'gentleman', 26: 'theology', 27: 'manners', 28: 'ezra', 29: 'stiles', 30: 'gannett', 31: 'honorable', 32: 'representative', 33: 'sanhedrin', 34: 'addressed', 35: 'frankly', 36: 'issue', 37: '1845', 38: 'insisting', 39: 'persecuted', 40: 'calumniated', 41: 'republic', 42: 'power', 43: 'restrain', 44: 'force', 45: 'exist', 46: 'judiciously', 47: 'argued', 48: 'association', 49: 'legitimately', 50: 'decide', 51: 'encouraged', 52: 'assisted', 53: 'diffusing', 54: 'opinions', 55: 'differ', 56: 'regard', 57: 'correctness', 58: 'today', 59: 'entitled', 60: 'excoriate', 61: 'honest', 62: 'men', 63: 'believed', 64: 'downright', 65: 'pernicious', 66: 'barred', 67: 'pulpits', 68: 'demand', 69: 'poison', 70: 'minds', 71: 'congregations'}\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def build_vocab(corpus: list[str]):\n",
    "    vocab = Counter(term for doc in corpus for term in doc)\n",
    "    word_to_idx = {word: idx for idx, (word, _) in enumerate(vocab.items())}\n",
    "    idx_to_word = {idx: word for idx, (word, _) in enumerate(vocab.items())}\n",
    "    return word_to_idx, idx_to_word\n",
    "\n",
    "word_to_idx, idx_to_word = build_vocab(cleaned_corpus[:5])\n",
    "print(word_to_idx)\n",
    "print(idx_to_word)\n",
    "print(len(word_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['furthermore', 'encouragement', 'revisionist'], 'furthermore'),\n",
       " (['furthermore', 'encouragement', 'revisionist', 'thinking'],\n",
       "  'encouragement'),\n",
       " (['furthermore', 'encouragement', 'revisionist', 'thinking', 'manifestly'],\n",
       "  'revisionist'),\n",
       " (['encouragement', 'revisionist', 'thinking', 'manifestly', 'fair'],\n",
       "  'thinking'),\n",
       " (['revisionist', 'thinking', 'manifestly', 'fair', 'admit'], 'manifestly')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_context_target_pairs(corpus: list[str], window_size: int = 2):\n",
    "    pairs = []\n",
    "    for document in corpus:\n",
    "        for idx, term in enumerate(document):\n",
    "            start_idx = max(idx - window_size, 0)\n",
    "            end_idx = min(idx + window_size + 1, len(document))\n",
    "            pairs.append(([document[i] for i in range(start_idx, end_idx)], term))\n",
    "\n",
    "    return pairs\n",
    "\n",
    "pairs = create_context_target_pairs(cleaned_corpus)\n",
    "pairs[:5]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([0, 1, 2], 0),\n",
       " ([0, 1, 2, 3], 1),\n",
       " ([0, 1, 2, 3, 4], 2),\n",
       " ([1, 2, 3, 4, 5], 3),\n",
       " ([2, 3, 4, 5, 6], 4)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_pairs(pairs: list[str], word_to_idx: dict):\n",
    "    encoded_pairs = []\n",
    "    for context, target in pairs:\n",
    "        context_idx = [word_to_idx[term] for term in context]\n",
    "        target_idx = word_to_idx[target]\n",
    "        encoded_pairs.append((context_idx, target_idx))\n",
    "\n",
    "    return encoded_pairs\n",
    "\n",
    "encoded_pairs = encode_pairs(pairs, word_to_idx)\n",
    "encoded_pairs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def convert_to_dataset(encoded_pairs: list, batch_size: int):\n",
    "    context_data, target_data = zip(*encoded_pairs)\n",
    "    context_tensors = [torch.tensor(context, dtype=torch.long) for context in context_data]\n",
    "    context_tensor = pad_sequence(context_tensors, batch_first=True)\n",
    "    target_tensor = torch.tensor(target_data, dtype=torch.long)\n",
    "    dataset = TensorDataset(context_tensor, target_tensor)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "def create_dataset(corpus: list[str], batch_size: int, test_size: float = 0.2) -> tuple[DataLoader, DataLoader, int]:\n",
    "    cleaned_corpus = clean_text(corpus)\n",
    "    word_to_idx, idx_to_word = build_vocab(cleaned_corpus)\n",
    "    pairs = create_context_target_pairs(cleaned_corpus)\n",
    "    encoded_pairs = encode_pairs(pairs, word_to_idx)\n",
    "    train_pairs, test_pairs = train_test_split(encoded_pairs, test_size=test_size, random_state=42)\n",
    "    return convert_to_dataset(train_pairs, batch_size), convert_to_dataset(test_pairs, batch_size), len(word_to_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.Embedding(vocab_size, embedding_dim)`: This creates a lookup table for the embeddings. It takes two arguments:\n",
    "- `vocab_size`: The size of the vocabulary (number of unique words in the corpus).\n",
    "- `embedding_dim`: The dimension of the embeddings.\n",
    "\n",
    "When you pass a tensor of indices to the `Embedding` layer, it looks up the embeddings for each index and returns a tensor of shape `(batch_size, sequence_length, embedding_dim)`.\n",
    "\n",
    "in the forward pass, the mean of the embeddings is taken and then passed to the linear layer. this is necessary as mean is a good choice for cbow model because:\n",
    "- Stability: Averaging smooths out noise and produces more stable representations.\n",
    "- Invariance to Context Size: Whether you have 2 or 10 context words, you get an embedding of the same dimension and approximate magnitude.\n",
    "- Computational Efficiency: It's simple and fast to compute.\n",
    "- Theoretical Interpretation: It can be interpreted as estimating the expected context embedding for a given target word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "class CBOWModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(CBOWModel, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
    "\n",
    "    def forward(self, context):\n",
    "        embedded = self.embeddings(context)\n",
    "        embedded = F.dropout(embedded, p=0.1)\n",
    "        embedded = embedded.mean(dim=1)\n",
    "        out = self.linear(embedded)\n",
    "        return out\n",
    "    \n",
    "    def predict(self, context):\n",
    "        logits = self(context)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        pred_idx = torch.argmax(probs, dim=1)\n",
    "        return pred_idx\n",
    "\n",
    "\n",
    "def train_model(model: nn.Module, train_loader: DataLoader, test_loader: DataLoader, epochs: int, learning_rate: float):\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    losses = []\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc=\"Training\", total=epochs):\n",
    "        total_loss = 0\n",
    "        test_loss = 0\n",
    "        model.train()\n",
    "        for X_train, y_train in train_loader:\n",
    "            y_logits = model(X_train) # forward pass\n",
    "            loss = loss_function(y_logits, y_train) # compute loss\n",
    "\n",
    "            optimizer.zero_grad() # set gradients to zero\n",
    "            loss.backward() # backward pass to compute gradients that are used to update the weights\n",
    "            optimizer.step() # update the weights\n",
    "            total_loss += loss.item() # add the loss to the total loss\n",
    "        losses.append(total_loss)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            for X_test, y_test in test_loader:\n",
    "                y_logits = model(X_test)\n",
    "                loss = loss_function(y_logits, y_test)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch} | Train Loss: {total_loss} | Test Loss: {test_loss}\")\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 1/100 [00:29<49:17, 29.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train Loss: 21643.038626670837 | Test Loss: 5388.9089012146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|██████▌   | 65/100 [33:54<18:15, 31.30s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m embedding_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m CBOWModel(vocab_size\u001b[38;5;241m=\u001b[39mvocab_size, embedding_dim\u001b[38;5;241m=\u001b[39membedding_dim)\n\u001b[0;32m----> 5\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# save model\u001b[39;00m\n\u001b[1;32m      8\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcbow_model.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 38\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, test_loader, epochs, learning_rate)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X_train, y_train \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     37\u001b[0m     y_logits \u001b[38;5;241m=\u001b[39m model(X_train) \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# compute loss\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad() \u001b[38;5;66;03m# set gradients to zero\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m# backward pass to compute gradients that are used to update the weights\u001b[39;00m\n",
      "File \u001b[0;32m~/code/nlu/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1549\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1546\u001b[0m             tracing_state\u001b[38;5;241m.\u001b[39mpop_scope()\n\u001b[1;32m   1547\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 1549\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapped_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1551\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loader, test_loader, vocab_size = create_dataset(corpus[:20000], 64)\n",
    "print(vocab_size)\n",
    "embedding_dim = 10\n",
    "model = CBOWModel(vocab_size=vocab_size, embedding_dim=embedding_dim)\n",
    "losses = train_model(model, train_loader, test_loader, epochs=100, learning_rate=0.0001)\n",
    "\n",
    "# save model\n",
    "torch.save(model.state_dict(), \"cbow_model.pt\")\n",
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "x=%{x}<br>y=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "xaxis": "x",
         "y": [
          21749.423342704773,
          21553.958910942078,
          21429.855387687683,
          21320.463097572327,
          21214.72582435608,
          21107.466492652893,
          20993.688634872437,
          20876.272495269775,
          20759.726093292236,
          20646.914357185364,
          20546.135542869568,
          20457.593572616577,
          20383.224588394165,
          20317.67644882202,
          20260.777190208435,
          20212.010272026062,
          20167.338619232178,
          20126.241956710815,
          20091.056330680847,
          20056.294399261475,
          20027.363191604614,
          19997.840125083923,
          19972.351035118103,
          19947.454043388367,
          19920.12966156006,
          19897.125695228577,
          19872.680198669434,
          19851.581699371338,
          19830.186186790466,
          19805.865942955017,
          19786.352292060852,
          19766.029638290405,
          19745.57808971405,
          19726.721792697906,
          19705.935436725616,
          19690.700729370117,
          19671.550539016724,
          19653.16325569153,
          19636.077702522278,
          19618.422676086426,
          19600.270559310913,
          19585.954464435577,
          19567.327440738678,
          19551.198551654816,
          19536.02995300293,
          19519.818872451782,
          19503.644731521606,
          19488.51885509491,
          19475.94893026352,
          19459.047353744507,
          19441.954659938812,
          19429.32950258255,
          19415.88205051422,
          19401.948254585266,
          19389.499935626984,
          19377.447160243988,
          19363.190084934235,
          19350.99491071701,
          19338.89625453949,
          19327.533603668213,
          19314.635487556458,
          19305.671871185303,
          19288.88696527481,
          19281.672905921936,
          19267.309032917023,
          19260.387012004852,
          19248.475198745728,
          19237.373878479004,
          19228.148659706116,
          19216.66763830185,
          19208.022136688232,
          19195.508257865906,
          19186.1014919281,
          19177.544544696808,
          19168.09406042099,
          19159.006361484528,
          19146.67786169052,
          19139.138940811157,
          19131.900934696198,
          19122.24512386322,
          19110.857448101044,
          19103.817708969116,
          19093.73246574402,
          19085.268335819244,
          19079.481905937195,
          19070.076680660248,
          19059.702394008636,
          19049.165325164795,
          19042.382753372192,
          19035.676576137543,
          19027.31103658676,
          19015.690665721893,
          19011.226613521576,
          19002.37526369095,
          18994.04848432541,
          18983.62023115158,
          18978.578112125397,
          18970.004430770874,
          18960.182440280914,
          18953.35403776169
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Loss Curve"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def loss_curve(losses: list[float]):\n",
    "    fig = px.line(x=range(len(losses)), y=losses, title='Loss Curve')\n",
    "    fig.show()\n",
    "\n",
    "loss_curve(losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17718, 5])\n",
      "torch.Size([17718])\n",
      "Accuracy: 0.05152951925992966\n",
      "Precision: 0.05152951925992966\n",
      "Recall: 0.05152951925992966\n",
      "F1 Score: 0.05152951925992966\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics import Accuracy, Precision, Recall, F1Score\n",
    "\n",
    "accuracy_fn = Accuracy(task=\"multiclass\", num_classes=vocab_size)\n",
    "precision_fn = Precision(task=\"multiclass\", num_classes=vocab_size)\n",
    "recall_fn = Recall(task=\"multiclass\", num_classes=vocab_size)\n",
    "f1_fn = F1Score(task=\"multiclass\", num_classes=vocab_size)\n",
    "\n",
    "\n",
    "X_test, y_test = torch.tensor([], dtype=torch.long), torch.tensor([], dtype=torch.long)\n",
    "for X, y in test_loader:\n",
    "    X_test = torch.cat((X_test, X), dim=0)\n",
    "    y_test = torch.cat((y_test, y), dim=0)\n",
    "\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred\n",
    "\n",
    "accuracy = accuracy_fn(y_pred, y_test)\n",
    "precision = precision_fn(y_pred, y_test)\n",
    "recall = recall_fn(y_pred, y_test)\n",
    "f1 = f1_fn(y_pred, y_test)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
